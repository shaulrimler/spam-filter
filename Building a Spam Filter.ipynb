{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c25bc9",
   "metadata": {},
   "source": [
    "# Detecting Spam Messages - a Naive Bayes' Algorithm Filter\n",
    "In this project we will be building an algorithm to detect spam messages. It is based on 5,000+ human classified messages and is trained using the Naive Bayes' algorithm.<br>\n",
    "The algorithm classifies new messages based on common words used in spam and non-spam messages. For the test set used in this project, it has a 98.7% accuracy rate. At the conclusion of this project, we will apply the algorithm to real life texts, and see how it holds up in realistic situations.<br>\n",
    "The text dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefa90e",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "We'll begin by reading in the dataset and getting a general overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c2471e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "texts = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "display(texts.head())\n",
    "display(texts.shape)\n",
    "display(texts['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a63c08",
   "metadata": {},
   "source": [
    "We could see that the dataset consists of 5,572 messages, 86% of which are non-spam. This is generally proportional, as most texts an average person receives are not spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ccead",
   "metadata": {},
   "source": [
    "## Train and test sets\n",
    "Now we'll split our dataset into two parts, a train set with which we will build our algorithm, and a test set to test it's accuracy. We'll use 80% for our train set and the remaining 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7dc8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomizing the data\n",
    "texts = texts.sample(frac=1, random_state=1)\n",
    "texts_train = texts[:4458].reset_index(drop=True)\n",
    "texts_test = texts[4458:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755445e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.86541\n",
       "spam    0.13459\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07debbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.868043\n",
       "spam    0.131957\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_test['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7680e54",
   "metadata": {},
   "source": [
    "We can see that the porpotions of spam and non-spam messages in both sections remain mostly unchanged, assuring that neither part is skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1c623",
   "metadata": {},
   "source": [
    "## Cleaning and Preparing the Training Set\n",
    "From here on out (until the testing phase) we'll be working with the training set. First we'll clean and reformat the dataset to prepare it for the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374ebdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformatting the texts into a series of lists\n",
    "texts_train['SMS'] = texts_train['SMS'].str.replace('\\W', ' ', regex=True).str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dca2130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [yep, by, the, pretty, sculpture]\n",
       "1    [yes, princess, are, you, going, to, make, me,...\n",
       "2                      [welp, apparently, he, retired]\n",
       "3                                             [havent]\n",
       "4    [i, forgot, 2, ask, ü, all, smth, there, s, a,...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train['SMS'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91599db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a vocabulary of all unique words found in the dataset\n",
    "vocabulary = []\n",
    "for row in texts_train['SMS']:\n",
    "    for word in row:\n",
    "        vocabulary.append(word)\n",
    "vocabulary = set(vocabulary)\n",
    "vocabulary = list(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2460c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary (and dataframe) of frequency counts of each word in all messages\n",
    "word_counts_per_sms = {unique_word: [0] * len(texts_train['SMS']) for unique_word in vocabulary}\n",
    "for index, sms in enumerate(texts_train['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d8377f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>october</th>\n",
       "      <th>lul</th>\n",
       "      <th>kl341</th>\n",
       "      <th>tb</th>\n",
       "      <th>mins</th>\n",
       "      <th>genuine</th>\n",
       "      <th>badrith</th>\n",
       "      <th>propsd</th>\n",
       "      <th>...</th>\n",
       "      <th>lag</th>\n",
       "      <th>facilities</th>\n",
       "      <th>comment</th>\n",
       "      <th>820554ad0a1705572711</th>\n",
       "      <th>round</th>\n",
       "      <th>finding</th>\n",
       "      <th>challenging</th>\n",
       "      <th>educational</th>\n",
       "      <th>pack</th>\n",
       "      <th>become</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  october  lul  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]        0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...        0    0   \n",
       "2   ham                    [welp, apparently, he, retired]        0    0   \n",
       "3   ham                                           [havent]        0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...        0    0   \n",
       "\n",
       "   kl341  tb  mins  genuine  badrith  propsd  ...  lag  facilities  comment  \\\n",
       "0      0   0     0        0        0       0  ...    0           0        0   \n",
       "1      0   0     0        0        0       0  ...    0           0        0   \n",
       "2      0   0     0        0        0       0  ...    0           0        0   \n",
       "3      0   0     0        0        0       0  ...    0           0        0   \n",
       "4      0   0     0        0        0       0  ...    0           0        0   \n",
       "\n",
       "   820554ad0a1705572711  round  finding  challenging  educational  pack  \\\n",
       "0                     0      0        0            0            0     0   \n",
       "1                     0      0        0            0            0     0   \n",
       "2                     0      0        0            0            0     0   \n",
       "3                     0      0        0            0            0     0   \n",
       "4                     0      0        0            0            0     0   \n",
       "\n",
       "   become  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train = pd.concat([texts_train, word_counts], axis=1)\n",
    "texts_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3762a43",
   "metadata": {},
   "source": [
    "At this point we have transformed our dataset into a series of columns indicating every unique word found in each message. This will help us iterate through this dataset when building our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b80fc4",
   "metadata": {},
   "source": [
    "## Building the Algorithm\n",
    "We are now ready to create our spam filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe4c6e",
   "metadata": {},
   "source": [
    "We'll begin by computing the constant variables that will be used in every new message:\n",
    "- p_spam - the probability of receiving a spam message\n",
    "- p_ham - the probability of receiving a non-spam message\n",
    "- n_spam - the number of (non-unique) words in spam messages\n",
    "- n_ham - the number of (non-unique) words in non-spam messages\n",
    "- n_vocabulary - the number of unique words in all messages\n",
    "- alpha - for additive smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5344117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = texts_train['Label'].value_counts(normalize=True)[1]\n",
    "p_ham = texts_train['Label'].value_counts(normalize=True)[0]\n",
    "spam_msg = texts_train[texts_train['Label'] == 'spam']\n",
    "ham_msg = texts_train[texts_train['Label'] == 'ham']\n",
    "n_spam = spam_msg['SMS'].apply(len).sum()\n",
    "n_ham = ham_msg['SMS'].apply(len).sum()\n",
    "n_vocabulary = len(vocabulary)\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ff7dd",
   "metadata": {},
   "source": [
    "We'll now build our algorithm, creating two dictionaries containing the conditional probability of every word in the vocabulary being par of a spam or non-spam message. When we recieve a new message to classify, all the calculations will already be computed, greatly speeding up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "697a4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dict = {unique_word: 0 for unique_word in vocabulary}\n",
    "ham_dict = {unique_word: 0 for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf94e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vocabulary:\n",
    "    n_word_spam = spam_msg[word].sum()\n",
    "    p_word_given_spam = (n_word_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    spam_dict[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_ham = ham_msg[word].sum()\n",
    "    p_word_given_ham = (n_word_ham + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    ham_dict[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e52dd",
   "metadata": {},
   "source": [
    "To illustrate what we have just created, we'll display a few words in each dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29f8dc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'october': 4.3529360553693465e-05,\n",
       " 'lul': 4.3529360553693465e-05,\n",
       " 'kl341': 0.0001305880816610804}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'october': 3.075976622577668e-05,\n",
       " 'lul': 3.075976622577668e-05,\n",
       " 'kl341': 1.537988311288834e-05}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dict(list(spam_dict.items())[:3]))\n",
    "display(dict(list(ham_dict.items())[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7829383b",
   "metadata": {},
   "source": [
    "Each word now has a number it is associated with in both the spam and ham dictionaries. This number is the (porportional) conditional probability that the word would end up in a spam or non-spam message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73aa6a",
   "metadata": {},
   "source": [
    "With this algorithm, we'll create a function that takes in the new message and returns the classification - either 'ham', 'spam', or 'requires human clarification' (in case there is equal chance it is a spam or non-spam message)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "344124d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in spam_dict:\n",
    "            p_spam_given_message *= spam_dict[word]\n",
    "        if word in ham_dict:\n",
    "            p_ham_given_message *= ham_dict[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'requires human clarification'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b891aa",
   "metadata": {},
   "source": [
    "## Measuring Classification Accuracy\n",
    "Now that we've created our algorithm, we'll put it to the test using our test set. Our algorithm should have at least an 80% accuracy rate for it to be considered reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e7ec90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_test['predicted'] = texts_test['SMS'].apply(classify)\n",
    "texts_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a64be80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1100\n",
      "Incorrect: 14\n",
      "Accuracy: 98.7%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(texts_test['SMS'])\n",
    "for row in texts_test.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "accuracy = correct / total\n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', '{}%'.format(round(accuracy, 3) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34303554",
   "metadata": {},
   "source": [
    "The accuracy rate is over 98%, which is well above our threshold. Overall, the algorithm misclassified only 14 out of 1,114 messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375270d5",
   "metadata": {},
   "source": [
    "Below, I'll list the 14 instances where the prediction was off. We can see that one message was determined as 'requires human clarification', and the rest were misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2fa953ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>requires human clarification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                                SMS  \\\n",
       "0   spam  Not heard from U4 a while. Call me now am here...   \n",
       "1   spam  More people are dogging in your area now. Call...   \n",
       "2    ham                  Unlimited texts. Limited minutes.   \n",
       "3    ham                                       26th OF JULY   \n",
       "4    ham                             Nokia phone is lovly..   \n",
       "5    ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "6    ham                   No calls..messages..missed calls   \n",
       "7    ham  We have sent JD for Customer Service cum Accou...   \n",
       "8   spam  Oh my god! I've found your number again! I'm s...   \n",
       "9   spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "10  spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "11  spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "12  spam                                      2/2 146tf150p   \n",
       "13  spam  Hello. We need some posh birds and chaps to us...   \n",
       "\n",
       "                       predicted  \n",
       "0                            ham  \n",
       "1                            ham  \n",
       "2                           spam  \n",
       "3                           spam  \n",
       "4                           spam  \n",
       "5   requires human clarification  \n",
       "6                           spam  \n",
       "7                           spam  \n",
       "8                            ham  \n",
       "9                            ham  \n",
       "10                           ham  \n",
       "11                           ham  \n",
       "12                           ham  \n",
       "13                           ham  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified = pd.DataFrame([])\n",
    "for i, row in texts_test.iterrows():\n",
    "    if row['Label'] != row['predicted']:\n",
    "        misclassified = pd.concat([misclassified, row], axis=1, ignore_index=True)\n",
    "misclassified = misclassified.transpose()\n",
    "misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca09513e",
   "metadata": {},
   "source": [
    "## Real-life Examples\n",
    "After creating this algorithm, I wanted to try it out on actual messages to get a sence of how it would perform in real life. I collected a handful of messages, 80% non-spam and 20% spam, and applied the algorithm to them. Let's see how it performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "365eb54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can we talk tonight?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey there isnt any bed sheet on one of the bed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Capital One wont call you for this code. The t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>But I still wanna know how work is going… And ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Was a close call but i miss my kids, ready to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>no.. we only have left some old cars for the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>FYI the mold test will take place today betwee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>I once looked it up in a jewish encyclopaedia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Updated link for Berris calendar https://calen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>U guys at 741? Should I come there? Wanna come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>Washer in Hotel works,.   Whoever needs Tide p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ham</td>\n",
       "      <td>The brixs arent quite where they want them. Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ham</td>\n",
       "      <td>I have one bedroom apartment available in 294 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>You can leave it at Rogers house. Ill get it l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi, i saw your listing on col for a short term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ham</td>\n",
       "      <td>My radio is dead can you bring a new battery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spam</td>\n",
       "      <td>High speed crash including athlete Tiger woods...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spam</td>\n",
       "      <td>dmlyn iqrco yokj http://easy.fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spam</td>\n",
       "      <td>heres a new way to stay stiff. its natural wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>[U.S.P.S]:While trying to send your parceI to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                SMS\n",
       "0    ham                               Can we talk tonight?\n",
       "1    ham  Hey there isnt any bed sheet on one of the bed...\n",
       "2    ham  Capital One wont call you for this code. The t...\n",
       "3    ham  But I still wanna know how work is going… And ...\n",
       "4    ham  Was a close call but i miss my kids, ready to ...\n",
       "5    ham  no.. we only have left some old cars for the w...\n",
       "6    ham  FYI the mold test will take place today betwee...\n",
       "7    ham  I once looked it up in a jewish encyclopaedia ...\n",
       "8    ham  Updated link for Berris calendar https://calen...\n",
       "9    ham  U guys at 741? Should I come there? Wanna come...\n",
       "10   ham  Washer in Hotel works,.   Whoever needs Tide p...\n",
       "11   ham  The brixs arent quite where they want them. Sa...\n",
       "12   ham  I have one bedroom apartment available in 294 ...\n",
       "13   ham  You can leave it at Rogers house. Ill get it l...\n",
       "14   ham  Hi, i saw your listing on col for a short term...\n",
       "15   ham       My radio is dead can you bring a new battery\n",
       "16  spam  High speed crash including athlete Tiger woods...\n",
       "17  spam               dmlyn iqrco yokj http://easy.fitness\n",
       "18  spam  heres a new way to stay stiff. its natural wit...\n",
       "19  spam  [U.S.P.S]:While trying to send your parceI to ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ham     0.8\n",
       "spam    0.2\n",
       "Name: label, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating the dataset\n",
    "non_spam = ['Can we talk tonight?', 'Hey there isnt any bed sheet on one of the beds. Can u bring one over?', 'Capital One wont call you for this code. The temporary code you requested is 288516. Please use this code to complete your request.', 'But I still wanna know how work is going… And stop WINING about it… Get it? Get it? I did that just in case mommy hasn’t yet', 'Was a close call but i miss my kids, ready to go home lol', 'no.. we only have left some old cars for the weekend :(', 'FYI the mold test will take place today between 11 and 1.', 'I once looked it up in a jewish encyclopaedia on last names and found the closest thing to its origin was a German town named very similar to it l, something like Rummel, and many years ago, Jews from Poland would travel there to trade (buy/sell) horses so those jewish families became known by last names having that root association. Bottom line, be proud of your yichud....as a most respectable and  prominent horse dealer! Todays equivalent would be a car dealer!', 'Updated link for Berris calendar https://calendly.com/berrihires/quick-hello',  'U guys at 741? Should I come there? Wanna come here for a little while? Something else?', 'Washer in Hotel works,.   Whoever needs Tide pods or quarters can ask the shift manager before leaving the plant', 'The brixs arent quite where they want them. Samples every 5-10 minutes', 'I have one bedroom apartment available in 294 Alabny It’s $175 per night $2,500 per month', 'You can leave it at Rogers house. Ill get it later', 'Hi, i saw your listing on col for a short term rental on carrol. Is it available for elul?', 'My radio is dead can you bring a new battery']\n",
    "spam = ['High speed crash including athlete Tiger woods leaves 4 dead :( http://notedwitness.boutique/G9Wo4MHo', 'dmlyn iqrco yokj http://easy.fitness', 'heres a new way to stay stiff. its natural without bad side effects highfor.online/VGGi7cn', '[U.S.P.S]:While trying to send your parceI to your address, we found that your details arent correct. Resolve this issue at https://reports-delivery.com/view']\n",
    "real_texts = pd.DataFrame(columns=['label', 'SMS'])\n",
    "for sms in non_spam:\n",
    "    real_texts.loc[len(real_texts)] = ['ham', sms]\n",
    "for sms in spam:\n",
    "    real_texts.loc[len(real_texts)] = ['spam', sms]\n",
    "display(real_texts)\n",
    "display(real_texts['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e8752d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can we talk tonight?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey there isnt any bed sheet on one of the bed...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Capital One wont call you for this code. The t...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>But I still wanna know how work is going… And ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Was a close call but i miss my kids, ready to ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>no.. we only have left some old cars for the w...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>FYI the mold test will take place today betwee...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>I once looked it up in a jewish encyclopaedia ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Updated link for Berris calendar https://calen...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>U guys at 741? Should I come there? Wanna come...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>Washer in Hotel works,.   Whoever needs Tide p...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ham</td>\n",
       "      <td>The brixs arent quite where they want them. Sa...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ham</td>\n",
       "      <td>I have one bedroom apartment available in 294 ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>You can leave it at Rogers house. Ill get it l...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi, i saw your listing on col for a short term...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ham</td>\n",
       "      <td>My radio is dead can you bring a new battery</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spam</td>\n",
       "      <td>High speed crash including athlete Tiger woods...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spam</td>\n",
       "      <td>dmlyn iqrco yokj http://easy.fitness</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spam</td>\n",
       "      <td>heres a new way to stay stiff. its natural wit...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>[U.S.P.S]:While trying to send your parceI to ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                SMS predicted\n",
       "0    ham                               Can we talk tonight?       ham\n",
       "1    ham  Hey there isnt any bed sheet on one of the bed...       ham\n",
       "2    ham  Capital One wont call you for this code. The t...      spam\n",
       "3    ham  But I still wanna know how work is going… And ...       ham\n",
       "4    ham  Was a close call but i miss my kids, ready to ...       ham\n",
       "5    ham  no.. we only have left some old cars for the w...       ham\n",
       "6    ham  FYI the mold test will take place today betwee...       ham\n",
       "7    ham  I once looked it up in a jewish encyclopaedia ...       ham\n",
       "8    ham  Updated link for Berris calendar https://calen...       ham\n",
       "9    ham  U guys at 741? Should I come there? Wanna come...       ham\n",
       "10   ham  Washer in Hotel works,.   Whoever needs Tide p...       ham\n",
       "11   ham  The brixs arent quite where they want them. Sa...       ham\n",
       "12   ham  I have one bedroom apartment available in 294 ...       ham\n",
       "13   ham  You can leave it at Rogers house. Ill get it l...       ham\n",
       "14   ham  Hi, i saw your listing on col for a short term...       ham\n",
       "15   ham       My radio is dead can you bring a new battery       ham\n",
       "16  spam  High speed crash including athlete Tiger woods...      spam\n",
       "17  spam               dmlyn iqrco yokj http://easy.fitness      spam\n",
       "18  spam  heres a new way to stay stiff. its natural wit...       ham\n",
       "19  spam  [U.S.P.S]:While trying to send your parceI to ...       ham"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 17\n",
      "Incorrect: 3\n",
      "Accuracy: 85.0%\n"
     ]
    }
   ],
   "source": [
    "# Applying the algorithm to our dataset\n",
    "real_texts['predicted'] = real_texts['SMS'].apply(classify)\n",
    "display(real_texts)\n",
    "correct = 0\n",
    "total = len(real_texts['SMS'])\n",
    "for i, row in real_texts.iterrows():\n",
    "    if row['label'] == row['predicted']:\n",
    "        correct += 1\n",
    "accuracy = correct / total\n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', '{}%'.format(round(accuracy, 3) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204fdfe",
   "metadata": {},
   "source": [
    "We can see that although the accuracy is still quite high, it has dropped significantly. Presumably, the origional dataset was working a stereotype of spam that may not always mirror the more realistic version used by modern spammers.<br>\n",
    "Upon closer inspection, you can see that the text misclassified as spam was an automated text (which has a strong resemblance to spam), which may account for that error. The problem seems to be primarily in catching spam messages that appear to be legitimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee02a8e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Overall, it seems that the algorithm itself performed incredibly well, and the underperformance with real world data was likely due to the dataset we used. Persumably, if a more realistic dataset were to be developed, this shortcome would be solved, and predictions would be reliable and realistic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
